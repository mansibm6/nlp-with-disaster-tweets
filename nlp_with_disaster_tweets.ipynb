{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_with_disaster_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoKBIxHrCeVG",
        "outputId": "1a69ec09-a4dc-4073-9092-c36b8efc22a7"
      },
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5001b2ae-386a-7dbe-9365-c88592db6f85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO8uP9bpMb7K"
      },
      "source": [
        "# Import Data and Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z5jgy6xDQzo",
        "outputId": "c6e28c47-5847-4fa4-f0fb-c59c7f64aa39"
      },
      "source": [
        "# Download Daniel Bourke's helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-18 05:44:13--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.2’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-18 05:44:13 (57.0 MB/s) - ‘helper_functions.py.2’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbO0ZFdcDf9X"
      },
      "source": [
        "# Import series of helper functions for the notebook \n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZcnr-12Dr2u",
        "outputId": "2e57bc2d-21ac-4d8b-caa7-8b5fe1a5330f"
      },
      "source": [
        "# Download the Natural Language Processing with Disaster Tweets dataset from Kaggle (here we use the one from ztm_tf_course which is the same as the one from kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-18 05:44:15--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.141.128, 142.251.2.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.2’\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-08-18 05:44:15 (146 MB/s) - ‘nlp_getting_started.zip.2’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbrkqSkNEQ2i"
      },
      "source": [
        "# Unzip the data\n",
        "unzip_data ('nlp_getting_started.zip')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "ZX1-RKspEZNG",
        "outputId": "e56b133d-2bb2-48dd-d6fb-59d7f3aaf33d"
      },
      "source": [
        "# Turn the csv files into pandas dataframe\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There's an emergency evacuation happening now ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "5   8     NaN  ...  #RockyFire Update => California Hwy. 20 closed...      1\n",
              "6  10     NaN  ...  #flood #disaster Heavy rain causes flash flood...      1\n",
              "7  13     NaN  ...  I'm on top of the hill and I can see a fire in...      1\n",
              "8  14     NaN  ...  There's an emergency evacuation happening now ...      1\n",
              "9  15     NaN  ...  I'm afraid that the tornado is coming to our a...      1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F13kn1glMnXH"
      },
      "source": [
        "# Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-agfKh6EFIYZ"
      },
      "source": [
        "# Shuffle the training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # frac is the fraction of dataframe to return and random_state value ensures reproducibility"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "GOIUz475GJ-r",
        "outputId": "6804bb23-beab-41dc-cc36-e8ec75912a5d"
      },
      "source": [
        "train_df_shuffled.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5559</th>\n",
              "      <td>7934</td>\n",
              "      <td>rainstorm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@Calum5SOS you look like you got caught in a r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1765</th>\n",
              "      <td>2538</td>\n",
              "      <td>collision</td>\n",
              "      <td>NaN</td>\n",
              "      <td>my favorite lady came to our volunteer meeting...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>2611</td>\n",
              "      <td>crashed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@brianroemmele UX fail of EMV - people want to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6810</th>\n",
              "      <td>9756</td>\n",
              "      <td>tragedy</td>\n",
              "      <td>Los Angeles, CA</td>\n",
              "      <td>Can't find my ariana grande shirt  this is a f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4398</th>\n",
              "      <td>6254</td>\n",
              "      <td>hijacking</td>\n",
              "      <td>Athens,Greece</td>\n",
              "      <td>The Murderous Story Of AmericaÛªs First Hijac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "5559  7934  ...      0\n",
              "1765  2538  ...      1\n",
              "1817  2611  ...      1\n",
              "6810  9756  ...      0\n",
              "4398  6254  ...      1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5jIpkpeGOg1"
      },
      "source": [
        "### We are going to write code to find the value of the target column based on the text column\n",
        "\n",
        "### Inputs (text coumn) --> Machine Learning Algorithm --> Outputs (target column)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "mdbM-LItGkTT",
        "outputId": "b8a8b940-9f58-46c5-a73c-df6336e59100"
      },
      "source": [
        "# The test data doesn't have a target column\n",
        "test_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS5c0yobHGUV",
        "outputId": "81faa369-94fc-4643-de9b-4dcccf977863"
      },
      "source": [
        "# Check how many examples of each target value we have\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RsPIpN5HTYs"
      },
      "source": [
        "### Since we have 2 target values, we are gonna be doing binary classification\n",
        "\n",
        "### Here, 1 is a real disaster Tweet and 0 is not a real disaster Tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUKD_sjQHcZu",
        "outputId": "856423cd-f6fb-4ea4-8c3c-6e43374bc38d"
      },
      "source": [
        "# Total number of samples we have\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df)+len(test_df)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmxCljN0ILZA",
        "outputId": "46405929-1aa3-4c54-a4e2-23ce0f673fdf"
      },
      "source": [
        "# Visualize random training examples\n",
        "import random # random generates pseudo-random numbers\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher then the number of samples\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples(): # returns the values of row as a tuple and loops over it\n",
        "  _, text, target = row # only get these two column values from each row\n",
        "  print(f'Target: {target}', '(real disaster)' if target > 0 else '(not real disaster)')\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print('---\\n')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@GreenLacey GodsLove &amp; #thankU my sister for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "It was finally demolished in the spring of 2013 and the property has sat vacant since. The justÛ_: saddlebrooke... http://t.co/Vcjcykq8b8\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "It's so freeing to name a new .doc 'NEWIDEA' and then get back to #writing w/out having derailed yourself thinking of a title. Or w/twitter.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I found a diamond in the rubble\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Crazy storm hit and I'm trapped inside a Hobby Lobby AMA http://t.co/8qc8Bcxoko\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkU3OGDjLid3"
      },
      "source": [
        "# Split the data into trainig and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSKDNA-9MvIt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(), # converts the dataframe to numpy array\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicates 10% of the samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr3RTI1nNyfP",
        "outputId": "6211fb93-2eb4-4dc5-d331-2a08b59302aa"
      },
      "source": [
        "# Check the lengths of the sets\n",
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZL39OO7N_8G",
        "outputId": "91477c78-efd3-4766-96c3-8f41af3ad7d1"
      },
      "source": [
        "# View first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFsblb5bOMsJ"
      },
      "source": [
        "# Converting Text Data to Numbers (Tokenization and Embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PPSQb_mOWgw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Initializing the text vectorizer\n",
        "text_vectorizer = TextVectorization(max_tokens=10000, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize = 'lower_and_strip_punctuation',# how to process text\n",
        "                                    split = 'whitespace', # how to split the tokens\n",
        "                                    ngrams = None, # create groups of n words\n",
        "                                    output_mode = 'int', # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long should the output sequence of tokens be\n",
        "                                    pad_to_max_tokens=True\n",
        "                                    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNK0JOyg0rnZ"
      },
      "source": [
        "### We set the max_tokens to 10,000 and we find the output_sequence_length which will be the average number of tokens per tweet in the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDi0Onup1Hul",
        "outputId": "6c7bfcd2-a2cd-44c2-be4c-3905ad99f00a"
      },
      "source": [
        "# Find the average number of tokens (words) in the training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc-bC4PM1af5"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_Length = 10000 # max number of words in our dataset\n",
        "max_length = 15 # max length of our sequences will be (how many words per tweet does our model see)\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_Length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3BViUB52J4g"
      },
      "source": [
        "# Fit the text vectorizer to the trainig text\n",
        "text_vectorizer.adapt(train_sentences) # adapt() maps text_vectorizer to out data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niHjpJEq2gGO",
        "outputId": "aa1cbab7-619b-4ee4-a596-6679aaad9cba"
      },
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCUDYYxx2xct"
      },
      "source": [
        "### What we have done is word level tokenization. Notice the 0's at the end of the returned tensor, this is because we set output_sequence_length=15, meaning no matter the size of the sequence we pass to text_vectorizer, it always returns a sequence with a length of 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELJyLBYB27g5",
        "outputId": "94640ac5-b444-4023-93f6-aaf34b7342cc"
      },
      "source": [
        "# Chose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original Text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Text:\n",
            "RT @AmznFavorites THE DEVEREAUX DISASTER. 'Exciting scifi #thriller...' http://t.co/Mw9amBgAfq #SciFi #Kindle      \n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  96,    1,    2,    1,   75, 5694, 3439, 2259,    1, 3439, 1827,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQT0Rf23juW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6a2d94-3b1e-4839-9031-603bad98fdfa"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # gets all the unique words in the vocabulary\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (UNK token means \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th1rTSLKJJjZ"
      },
      "source": [
        "## Create an Embedding using Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEho--x3JRf1"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "# Initialize the Embedding layer\n",
        "embedding = layers.Embedding(input_dim=max_vocab_Length, # set the input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, initialize randomly\n",
        "                             input_length=max_length)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI2KMmWqKDq1",
        "outputId": "ebed9ec4-ea8f-495c-ffa7-05d8120d0efa"
      },
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original Text:\\n {random_sentence}\\\n",
        "\\n\\nEmbedded Version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representaion)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Text:\n",
            " 5/6 will destroy Reg C competitiveness.   The entire region will B over-saturated.   Yes Brockton gets $12M and RegC Commonwealth PPC and\n",
            "\n",
            "Embedded Version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00360912,  0.04432975,  0.00230187, ..., -0.02465419,\n",
              "          0.02451265, -0.03434109],\n",
              "        [-0.04320616,  0.01726519, -0.01462676, ...,  0.047023  ,\n",
              "          0.04709803, -0.00514233],\n",
              "        [-0.03551704, -0.01103346, -0.03134266, ...,  0.03498955,\n",
              "         -0.00519005,  0.04889769],\n",
              "        ...,\n",
              "        [ 0.00375974,  0.00817446, -0.04364332, ...,  0.03330666,\n",
              "          0.03759719, -0.0204911 ],\n",
              "        [ 0.02002515,  0.00983226, -0.01081201, ...,  0.02367267,\n",
              "         -0.01422318, -0.03963244],\n",
              "        [ 0.00169345,  0.02608505,  0.01718011, ...,  0.03149169,\n",
              "          0.01276172, -0.03408507]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae6_VfphKti1"
      },
      "source": [
        "### Each token in the sentence gets turned into a length 128 feature vector. Each sentence has 15 tokens. That's why the shape is 1, 15, 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDFE_xMyLAQz",
        "outputId": "e75338f9-cad6-480e-8fde-519d3c61184c"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 3.6091208e-03,  4.4329751e-02,  2.3018718e-03, -1.1275839e-02,\n",
              "       -1.0211457e-02,  5.8976635e-03,  3.2003488e-02,  7.2542429e-03,\n",
              "        4.0869262e-02, -3.4501888e-02, -4.5203995e-02,  4.0542517e-02,\n",
              "        3.4782115e-02, -4.5295563e-02,  3.5314355e-02, -3.1369973e-02,\n",
              "        2.1963958e-02, -2.2265971e-02, -2.3108236e-03, -1.6997010e-04,\n",
              "        1.8542659e-02, -4.8918772e-02,  4.1039418e-02,  4.2511821e-03,\n",
              "        1.8932570e-02, -3.6871135e-02,  1.3811477e-03,  1.5152384e-02,\n",
              "        3.6678527e-02,  6.6074505e-03,  6.0535967e-05,  2.8665174e-02,\n",
              "       -1.5963208e-02, -3.4892499e-02, -8.4078684e-03,  3.1673972e-02,\n",
              "       -4.3817844e-02, -1.5275799e-02, -2.0707512e-02,  2.3119774e-02,\n",
              "       -5.3257942e-03,  2.8534267e-02,  1.0083772e-02,  4.6621609e-02,\n",
              "       -2.1574557e-02,  1.1500977e-02,  1.5444923e-02, -3.9726306e-02,\n",
              "       -3.9109088e-02, -4.4067468e-02, -4.9886048e-02,  3.1835560e-02,\n",
              "        3.3748735e-02,  3.5806481e-02,  3.9198343e-02,  1.7332342e-02,\n",
              "        3.1973604e-02, -5.3548105e-03,  7.7552311e-03,  3.0977491e-02,\n",
              "       -2.0837044e-02, -1.6186237e-02, -2.7544474e-02, -1.8619288e-02,\n",
              "       -3.4276389e-02,  2.8464507e-02, -1.8136322e-02,  1.4127005e-02,\n",
              "        2.8102968e-02, -1.1228956e-02,  4.8372004e-02, -7.6725110e-03,\n",
              "        3.1729948e-02,  1.1836134e-02, -4.8607316e-02, -4.1795596e-03,\n",
              "        1.9164715e-02, -3.4948587e-02,  4.3687072e-02,  2.7677607e-02,\n",
              "       -1.2924790e-02, -2.0370377e-02,  1.1157572e-02, -1.7099213e-02,\n",
              "        3.0873489e-02, -2.4731029e-02,  4.5552444e-02, -1.3975263e-02,\n",
              "       -2.3857368e-02, -4.2436052e-02, -3.1493247e-02, -1.5126992e-02,\n",
              "       -1.7994095e-02,  3.1372372e-02, -4.1661751e-02, -4.5842733e-02,\n",
              "        2.6358131e-02,  4.4608738e-02,  1.9665409e-02, -3.5617232e-02,\n",
              "        1.2691841e-03,  1.1596870e-02,  1.0690987e-02,  4.9185667e-02,\n",
              "       -3.7112903e-02, -6.0583465e-03, -2.2341847e-02, -4.1492570e-02,\n",
              "        1.2045562e-02, -1.1234295e-02,  4.7391426e-02, -4.5517515e-02,\n",
              "        3.3135418e-02, -2.0989168e-02, -1.7624736e-02, -3.6286343e-02,\n",
              "        7.7534318e-03,  4.0261898e-02, -4.1224301e-02,  1.9378010e-02,\n",
              "       -4.3016173e-02,  3.9508667e-02, -4.1975211e-02, -7.9521909e-03,\n",
              "       -3.0546367e-02, -2.4654185e-02,  2.4512652e-02, -3.4341086e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y9wdzuhLPZJ"
      },
      "source": [
        "# Create Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRbjOsL4L4e1"
      },
      "source": [
        "### Steps to go through:\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rs2xlckLz99"
      },
      "source": [
        "## Model 0: Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ4WBWZbMTyB"
      },
      "source": [
        "### To create out baseline model to get a benchmark for future experiments to build upon, er create a scikit-learn pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinominal Naive Bayes algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSIzo55IM9CH",
        "outputId": "fa7ccf69-b8b6-4aed-d829-5975f8083564"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    ('tfidf', TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyPl1yoIN0eR"
      },
      "source": [
        "### Evaluate the model to find the baseline metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LquVZ_8HN_S5",
        "outputId": "17bc7a00-5688-462a-b589-be2eec13af83"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR9l9Lb2OUxs",
        "outputId": "c62c38bc-d42b-4a60-8981-da66e456b2b2"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu2Ufvv9QsVU"
      },
      "source": [
        "## Creating an evaluation function for our model experiments\n",
        "\n",
        "Takes an array of predictions and ground truth labels and computes the following:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D1xxKhkQ2Xg"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18k3i-LD1V3",
        "outputId": "537e4a1c-271c-4aad-d8b8-9de068f072a1"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HZCylBaEikm"
      },
      "source": [
        "## Model 1: Simple Dense Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA6QzWauEyiU"
      },
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save tensorboard logs\n",
        "SAVE_DIR = 'model_logs'"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcKHpC9XFENn"
      },
      "source": [
        "# Build the model with the functional API\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1 dimensional strings\n",
        "x = text_vectorizer(inputs) # turns input texts into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embeddings\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create output layer, we want binary outputs so we use sigmoid activation (for categorical use softmax)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # constructs the model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBSXUD1JGoeX"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC0LYeRvH9e_",
        "outputId": "f9e6c5c2-2f80-4e1a-df06-780930cdc0a1"
      },
      "source": [
        "# Get summary of model_1\n",
        "model_1.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khntlTjqIDkj"
      },
      "source": [
        "### We created an embedding of soze 128 for a vocabulary of 10,000. So 128 x 10,000 = 1280000 parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI_2MuQqIeuf",
        "outputId": "dd55d8dd-9ce0-4a64-e006-ea7cf1c6428a"
      },
      "source": [
        "# Fit the model to training data for 5 epochs\n",
        "model_1.history = model_1.fit(train_sentences, \n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                       experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20210818-054423\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 7ms/step - loss: 0.6104 - accuracy: 0.6993 - val_loss: 0.5387 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.4429 - accuracy: 0.8158 - val_loss: 0.4679 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8593 - val_loss: 0.4589 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2841 - accuracy: 0.8926 - val_loss: 0.4636 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 4ms/step - loss: 0.2378 - accuracy: 0.9118 - val_loss: 0.4791 - val_accuracy: 0.7887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI7BF1y5JDLW",
        "outputId": "788e5cb1-8704-4abf-f29d-30432fb05219"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47907575964927673, 0.7887139320373535]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_g9s8jZJSLT",
        "outputId": "ea06d501-8494-4fda-8dec-e055ae8d6331"
      },
      "source": [
        "# Make predictions (these comeback in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29977   ],\n",
              "       [0.7241453 ],\n",
              "       [0.9979164 ],\n",
              "       [0.11123318],\n",
              "       [0.12252843],\n",
              "       [0.9316711 ],\n",
              "       [0.9086821 ],\n",
              "       [0.9923828 ],\n",
              "       [0.96130884],\n",
              "       [0.26767737]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BenK9ygELGlk"
      },
      "source": [
        "### Since we used a sigmoid function, our predictions come back in the form of probabilities. To convert predictions to classes, we round them with a threshold value of 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdAhlGSNLR5S",
        "outputId": "669f7441-e7f0-46fa-9b4e-a9e2a42e2d52"
      },
      "source": [
        "# Turn prediction probabilities into single dimensional tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MZlHMIiL44M"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htri1JqPMFFK",
        "outputId": "07353845-9e30-4e52-a772-d1e158fa1211"
      },
      "source": [
        "model_1_results"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.87139107611549,\n",
              " 'f1': 0.7852145092095362,\n",
              " 'precision': 0.7953441303708004,\n",
              " 'recall': 0.7887139107611548}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anCFzsilMH1l",
        "outputId": "6634c517-444b-4d32-e183-65e71116f622"
      },
      "source": [
        "# Is our simple Keras model better than our baseline model\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QS-wnS1MeGn"
      },
      "source": [
        "## We creat a new function to compare any model to our baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKu5-vdWMzVK",
        "outputId": "8921e59d-b060-489b-d472-1d13fe97cd5b"
      },
      "source": [
        "# Create a helper function to compare our baseline results to our new models\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results,\n",
        "                                new_model_results=model_1_results)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.87, Difference: -0.39\n",
            "Baseline precision: 0.81, New precision: 0.80, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.00\n",
            "Baseline f1: 0.79, New f1: 0.79, Difference: -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDIUTUJxNiEY"
      },
      "source": [
        "### Our first model (model_1) contained an embedding layer which learned a way of representing words as feature vectors by passing over the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slO9OUJYDZtX",
        "outputId": "bd0585d4-299d-4757-c355-c79331cdd12d"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nRMDk8kDr_F"
      },
      "source": [
        "### Let's take a look at the embedding layer's weights (these are numerical representations of each word)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G4cd_X3EjkK",
        "outputId": "6d551d6d-9438-4d84-e165-f405b2440457"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPPgURXiEmS0",
        "outputId": "c7aaa348-31f7-42e7-9f08-bb4e61ba5ce2"
      },
      "source": [
        "# Get the weight matrix of the embedding layer\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (each word is a embedding size vector)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCHjRGSfFaye"
      },
      "source": [
        "## Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC1DsZ-FGXgz"
      },
      "source": [
        "## Model 2:LSTM (Long short term memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ae2LPgGe7Q",
        "outputId": "90bc200a-963d-41cb-ba84-1fef02c6ad28"
      },
      "source": [
        "# Create our LSTM Model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IUJkoxGITzm"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLa4LBGhntEP",
        "outputId": "2daa91d5-1970-4476-9d8b-1d07e7ee6f88"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEuXhAwsoOfJ",
        "outputId": "30789833-aa90-4423-c1ba-745a22f96b24"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"LSTM\")])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20210818-054435\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 12ms/step - loss: 0.2111 - accuracy: 0.9272 - val_loss: 0.5785 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1570 - accuracy: 0.9423 - val_loss: 0.6428 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.1285 - accuracy: 0.9514 - val_loss: 0.6514 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1028 - accuracy: 0.9597 - val_loss: 0.8756 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0840 - accuracy: 0.9657 - val_loss: 1.1347 - val_accuracy: 0.7730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK3wgl0Sovvn",
        "outputId": "2923cf71-33dc-4e37-bd1f-06c33d16015c"
      },
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[1.5951982e-03],\n",
              "        [8.0798143e-01],\n",
              "        [9.9981695e-01],\n",
              "        [1.3878454e-02],\n",
              "        [2.6173526e-04],\n",
              "        [9.9906045e-01],\n",
              "        [9.5776582e-01],\n",
              "        [9.9987423e-01],\n",
              "        [9.9977547e-01],\n",
              "        [6.9741303e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up2F6hiBpOwL",
        "outputId": "b3e9fa9f-7738-4243-c9cf-387978627d63"
      },
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-LkuvbBphgO",
        "outputId": "0f31b960-bc4e-42ff-af20-31973b611c34"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'f1': 0.7710949612836401,\n",
              " 'precision': 0.7742755789705,\n",
              " 'recall': 0.7729658792650919}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBERk2yopzUX",
        "outputId": "4ba4ef88-dd3b-42aa-b48d-06a51849e640"
      },
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.30, Difference: -1.97\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIGCDhRMqFZI"
      },
      "source": [
        "## Model 3:GRU (Gated Recurrent Unit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSlllGK0qOl2"
      },
      "source": [
        "# Build an RNN model using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x=layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"Model_3_GRU\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL5M4LuSrNB0"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3luGrKh_rbxO",
        "outputId": "a5216e25-3b9b-4013-b241-5c4a8a7f1dd2"
      },
      "source": [
        "# Get summary of the model\n",
        "model_3.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsNqGcXVrlj3"
      },
      "source": [
        "### LSTM cells have more trainable parameters than GRU cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8Huf8uZrwkK",
        "outputId": "66bd1fad-a0b1-4ba4-e61b-b5a987cd92e9"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\" )])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20210818-054458\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 10ms/step - loss: 0.1552 - accuracy: 0.9409 - val_loss: 0.8067 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0813 - accuracy: 0.9693 - val_loss: 0.9969 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0680 - accuracy: 0.9733 - val_loss: 0.9393 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0575 - accuracy: 0.9746 - val_loss: 1.1687 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0508 - accuracy: 0.9784 - val_loss: 1.1899 - val_accuracy: 0.7795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33TDDOzFsFjI",
        "outputId": "4111390b-2f72-4622-fd9e-470a6347210e"
      },
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[6.5848965e-04],\n",
              "        [7.7392125e-01],\n",
              "        [9.9985337e-01],\n",
              "        [6.2067371e-02],\n",
              "        [1.3768836e-04],\n",
              "        [9.9972278e-01],\n",
              "        [8.6527115e-01],\n",
              "        [9.9993181e-01],\n",
              "        [9.9989402e-01],\n",
              "        [8.7438649e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pSkaWNpsl_I",
        "outputId": "f9d8f705-d374-4d92-e2fd-60f81260c25f"
      },
      "source": [
        "# Convert the prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD5-fwo3s1w1",
        "outputId": "6a75d8bc-e91f-446f-de89-4e1a929c51af"
      },
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "\n",
        "model_3_results"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'f1': 0.7776506830100394,\n",
              " 'precision': 0.7811151206076258,\n",
              " 'recall': 0.7795275590551181}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msTsfcMntGVr",
        "outputId": "43e7c8c3-1c79-45af-804f-285e658948bc"
      },
      "source": [
        "# Comapare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.95, Difference: -1.31\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcGcz-QUtYiN"
      },
      "source": [
        "## Model 4:Bidirectional RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8ErPZ1ste8F"
      },
      "source": [
        "# Build bidirectional RNN with tensorflow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1, ), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional_RNN\")"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbxMdbDlwIxv"
      },
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI4-E9Acwbw-",
        "outputId": "8bcbd2cb-e0c5-4aad-bf7f-684fd9dec772"
      },
      "source": [
        "# Get model summary\n",
        "model_4.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_Bidirectional_RNN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QieMiMdwhlu",
        "outputId": "9e78193d-3207-4c5a-fb16-0cff0101af55"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,\n",
        "                                               val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"Bidirectional_RNN\")])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Bidirectional_RNN/20210818-054508\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 14ms/step - loss: 0.1028 - accuracy: 0.9701 - val_loss: 0.9617 - val_accuracy: 0.7585\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0526 - accuracy: 0.9772 - val_loss: 1.1399 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0442 - accuracy: 0.9794 - val_loss: 1.4102 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0496 - accuracy: 0.9794 - val_loss: 1.0429 - val_accuracy: 0.7598\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0451 - accuracy: 0.9793 - val_loss: 1.2878 - val_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWE9K4Rqw76r"
      },
      "source": [
        "# Make predictions with bidirectional RNN on validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YivLxtqoxUY3",
        "outputId": "7c5bea91-b90f-4ed3-c1e8-b73583ebbad2"
      },
      "source": [
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1863598e-02],\n",
              "       [8.3610344e-01],\n",
              "       [9.9985409e-01],\n",
              "       [2.6843926e-01],\n",
              "       [1.0610354e-05],\n",
              "       [9.9912828e-01],\n",
              "       [8.3284414e-01],\n",
              "       [9.9997044e-01],\n",
              "       [9.9992275e-01],\n",
              "       [7.0323658e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wve4ZSXAxXvm",
        "outputId": "cc0c1436-fbcb-4406-ed23-4af769903355"
      },
      "source": [
        "# Convert the prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thjxY8iJxr5J",
        "outputId": "c0af67ea-0570-4c82-9b4d-ebc1cd1a3b15"
      },
      "source": [
        "# Calculate bidirectional RNN results\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7683227325217538,\n",
              " 'precision': 0.7718252603398367,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3hPI4iAx9Bl",
        "outputId": "bf763d27-53ea-4e01-e19f-aa47113e6ce6"
      },
      "source": [
        "# Check performance against baseline model\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n0wn6gyyLKd"
      },
      "source": [
        "## Using CNNs for Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2roqa3Iyewo"
      },
      "source": [
        "## Model 5:Conv1D (Temporal Convolution)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka_SPXW8yhiw",
        "outputId": "0c65f4d2-b7b1-4c7a-a722-d760acd43e73"
      },
      "source": [
        "# Test out the embedding, 1D convolution and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalAveragePooling1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ8Osmenz5EK",
        "outputId": "e5b1f1da-46b5-4265-d5a3-885766cd8a31"
      },
      "source": [
        "# See the outputs of each layer\n",
        "embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              " array([[[ 0.0380373 ,  0.03715516, -0.01305072, ...,  0.01131982,\n",
              "           0.00947844, -0.0318321 ],\n",
              "         [-0.07146953, -0.00405229,  0.00722739, ..., -0.00029891,\n",
              "          -0.05608712, -0.05828224],\n",
              "         [-0.02481517,  0.03885648,  0.01064512, ...,  0.06255261,\n",
              "          -0.01695915, -0.03550133],\n",
              "         ...,\n",
              "         [ 0.01567172,  0.00294966,  0.02651889, ...,  0.03134949,\n",
              "           0.02203247, -0.02747479],\n",
              "         [ 0.01567172,  0.00294966,  0.02651889, ...,  0.03134949,\n",
              "           0.02203247, -0.02747479],\n",
              "         [ 0.01567172,  0.00294966,  0.02651889, ...,  0.03134949,\n",
              "           0.02203247, -0.02747479]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              " array([[[0.        , 0.03416327, 0.        , 0.07907262, 0.        ,\n",
              "          0.10150522, 0.00970192, 0.04804736, 0.        , 0.        ,\n",
              "          0.02350046, 0.04065965, 0.        , 0.02061619, 0.07634187,\n",
              "          0.07246906, 0.03264775, 0.01322698, 0.02443944, 0.01289758,\n",
              "          0.11538003, 0.02154797, 0.        , 0.        , 0.00111956,\n",
              "          0.        , 0.        , 0.00856475, 0.05132878, 0.10509367,\n",
              "          0.        , 0.00064828],\n",
              "         [0.0247761 , 0.        , 0.        , 0.        , 0.05532138,\n",
              "          0.06392856, 0.        , 0.        , 0.04869912, 0.        ,\n",
              "          0.        , 0.03028064, 0.        , 0.        , 0.        ,\n",
              "          0.03805367, 0.        , 0.        , 0.14914456, 0.04817423,\n",
              "          0.02041261, 0.        , 0.        , 0.        , 0.01469939,\n",
              "          0.        , 0.        , 0.01380207, 0.03160469, 0.08775178,\n",
              "          0.        , 0.06969921],\n",
              "         [0.07389721, 0.        , 0.00373272, 0.        , 0.01611781,\n",
              "          0.04886591, 0.        , 0.01435758, 0.04593275, 0.        ,\n",
              "          0.04726057, 0.0045663 , 0.        , 0.        , 0.        ,\n",
              "          0.        , 0.        , 0.03515336, 0.02450512, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.02588128,\n",
              "          0.        , 0.        , 0.        , 0.        , 0.0529357 ,\n",
              "          0.        , 0.        ],\n",
              "         [0.        , 0.        , 0.02653255, 0.        , 0.        ,\n",
              "          0.00547036, 0.        , 0.        , 0.        , 0.        ,\n",
              "          0.0708462 , 0.00323386, 0.        , 0.        , 0.01137741,\n",
              "          0.02910442, 0.        , 0.02017425, 0.04981795, 0.        ,\n",
              "          0.01796616, 0.03803843, 0.        , 0.        , 0.04369608,\n",
              "          0.        , 0.        , 0.00940793, 0.0633743 , 0.        ,\n",
              "          0.00525753, 0.        ],\n",
              "         [0.0259371 , 0.        , 0.05974115, 0.00560163, 0.        ,\n",
              "          0.        , 0.05528609, 0.        , 0.03112631, 0.        ,\n",
              "          0.03536663, 0.        , 0.0001833 , 0.        , 0.        ,\n",
              "          0.03040299, 0.        , 0.02906953, 0.04482245, 0.        ,\n",
              "          0.        , 0.02841846, 0.        , 0.        , 0.00111543,\n",
              "          0.        , 0.00585447, 0.        , 0.00382902, 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.02148411, 0.02311372, 0.04968635, 0.03313067, 0.        ,\n",
              "          0.        , 0.04849334, 0.        , 0.01807348, 0.        ,\n",
              "          0.04609378, 0.        , 0.        , 0.        , 0.00194293,\n",
              "          0.016428  , 0.        , 0.01742218, 0.04337957, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01871897, 0.        ,\n",
              "          0.        , 0.00594966, 0.00165119, 0.        , 0.02601756,\n",
              "          0.        , 0.        ],\n",
              "         [0.02148412, 0.02311372, 0.04968636, 0.03313068, 0.        ,\n",
              "          0.        , 0.04849336, 0.        , 0.01807348, 0.        ,\n",
              "          0.04609378, 0.        , 0.        , 0.        , 0.00194293,\n",
              "          0.016428  , 0.        , 0.01742218, 0.04337956, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01871897, 0.        ,\n",
              "          0.        , 0.00594966, 0.00165118, 0.        , 0.02601755,\n",
              "          0.        , 0.        ],\n",
              "         [0.02148412, 0.02311372, 0.04968635, 0.03313067, 0.        ,\n",
              "          0.        , 0.04849336, 0.        , 0.01807348, 0.        ,\n",
              "          0.04609378, 0.        , 0.        , 0.        , 0.00194294,\n",
              "          0.016428  , 0.        , 0.01742218, 0.04337955, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01871897, 0.        ,\n",
              "          0.        , 0.00594965, 0.00165118, 0.        , 0.02601756,\n",
              "          0.        , 0.        ],\n",
              "         [0.02148413, 0.02311372, 0.04968636, 0.03313067, 0.        ,\n",
              "          0.        , 0.04849336, 0.        , 0.01807348, 0.        ,\n",
              "          0.04609378, 0.        , 0.        , 0.        , 0.00194294,\n",
              "          0.016428  , 0.        , 0.01742218, 0.04337956, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01871897, 0.        ,\n",
              "          0.        , 0.00594966, 0.00165118, 0.        , 0.02601756,\n",
              "          0.        , 0.        ],\n",
              "         [0.02148413, 0.02311373, 0.04968636, 0.03313067, 0.        ,\n",
              "          0.        , 0.04849335, 0.        , 0.01807348, 0.        ,\n",
              "          0.04609378, 0.        , 0.        , 0.        , 0.00194293,\n",
              "          0.01642799, 0.        , 0.01742218, 0.04337957, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01871897, 0.        ,\n",
              "          0.        , 0.00594966, 0.00165118, 0.        , 0.02601756,\n",
              "          0.        , 0.        ],\n",
              "         [0.02148412, 0.02311372, 0.04968636, 0.03313067, 0.        ,\n",
              "          0.        , 0.04849335, 0.        , 0.01807348, 0.        ,\n",
              "          0.04609377, 0.        , 0.        , 0.        , 0.00194293,\n",
              "          0.016428  , 0.        , 0.01742218, 0.04337956, 0.        ,\n",
              "          0.        , 0.        , 0.        , 0.01871897, 0.        ,\n",
              "          0.        , 0.00594965, 0.00165118, 0.        , 0.02601756,\n",
              "          0.        , 0.        ]]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              " array([[2.3046829e-02, 1.5713235e-02, 3.5284054e-02, 2.5768936e-02,\n",
              "         6.4944718e-03, 1.9979095e-02, 3.2358918e-02, 5.6731761e-03,\n",
              "         2.1290820e-02, 0.0000000e+00, 4.1230585e-02, 7.1582231e-03,\n",
              "         1.6664027e-05, 1.8741990e-03, 9.0342602e-03, 2.4418009e-02,\n",
              "         2.9679770e-03, 1.8377928e-02, 5.0273348e-02, 5.5519827e-03,\n",
              "         1.3978073e-02, 8.0004418e-03, 0.0000000e+00, 1.0210346e-02,\n",
              "         7.8647044e-03, 0.0000000e+00, 3.7774914e-03, 3.7892587e-03,\n",
              "         1.3648799e-02, 3.6535133e-02, 4.7795719e-04, 6.3952254e-03]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsZ8Jv03Z2JN",
        "outputId": "0f0e98a9-4eae-4443-fb49-a22930329407"
      },
      "source": [
        "# Create 1D convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Summary of the model\n",
        "model_5.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 32)            20512     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcU3xX0EcLM_",
        "outputId": "5a888968-6863-42b4-9262-47305b9e8fd3"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"Conv1D\")])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210818-054545\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 9ms/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.8353 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0755 - accuracy: 0.9721 - val_loss: 1.0018 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0610 - accuracy: 0.9765 - val_loss: 1.0895 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0552 - accuracy: 0.9778 - val_loss: 1.1728 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0505 - accuracy: 0.9787 - val_loss: 1.1974 - val_accuracy: 0.7585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na3ozgVdcnRi",
        "outputId": "f7cc8afc-853d-434b-bab7-2fb9ce619811"
      },
      "source": [
        "# Make predictions with model 5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5452504e-01],\n",
              "       [7.7987003e-01],\n",
              "       [9.9993563e-01],\n",
              "       [1.0218226e-01],\n",
              "       [4.6757950e-07],\n",
              "       [9.9907386e-01],\n",
              "       [9.9475938e-01],\n",
              "       [9.9994576e-01],\n",
              "       [9.9999964e-01],\n",
              "       [7.7219975e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3TXXDruc41e",
        "outputId": "5739c0b7-1d32-4811-cd9d-b97d34033e6e"
      },
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cTFtLLZeeKX",
        "outputId": "78abe9de-c7d3-4c50-f2cb-47c0f23bd42d"
      },
      "source": [
        "# Calculate model_5 evaluation metrics\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "\n",
        "model_5_results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'f1': 0.7573131746360092,\n",
              " 'precision': 0.7584850115306213,\n",
              " 'recall': 0.7585301837270341}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxQO4JjGeveJ",
        "outputId": "8b37422c-fdd9-4adb-8e7c-c42515ba9ce6"
      },
      "source": [
        "# Compare model 5 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.85, Difference: -3.41\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZw4N5Z2e1_l"
      },
      "source": [
        "## Model 6:Tensorsflow hub pretrained sentence encoder (encoder-decoder model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reRNFLDHfPpn",
        "outputId": "968bf10c-d0d0-45f5-a9d0-42fdeaca572c"
      },
      "source": [
        "# Example of pretrained embedding with universal sentence encoder\n",
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load universal sentence encoder\n",
        "embed_samples = embed([sample_sentence, \"when you call universal sentence encoder on a sentence, it turns it into numbers\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
            "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865346 -0.04209305  0.0267898   0.03011008  0.00321069\n",
            " -0.00337971 -0.04787356  0.02266719 -0.00985925 -0.04063613 -0.01292093\n",
            " -0.04666384  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014441\n",
            "  0.02871508  0.04947684 -0.00633978 -0.08960193  0.02807117 -0.00808362\n",
            " -0.01360601  0.0599865  -0.10361787 -0.05195374  0.00232955 -0.0233253\n",
            " -0.03758105  0.03327729], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWS6mJMegpGY",
        "outputId": "c3faea86-2d1b-48e1-f843-0de4ab542a8c"
      },
      "source": [
        "# Each sentence has been encoded to a 512 dimension vector\n",
        "embed_samples.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmWHORtIhIcN"
      },
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model\n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (Feature Extraction)\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDgbwqlqihdm",
        "outputId": "fc5e419d-a78b-4dbf-c092-c4810f5d55c0"
      },
      "source": [
        "# Create model using sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "                               layers.Dense(64, activation=\"relu\"),\n",
        "                               layers.Dense(1, activation=\"sigmoid\")], name=\"model_6_USE\")\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Summary of the model\n",
        "model_6.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1gO3xnLl1O7",
        "outputId": "16e5c846-d3f0-40f5-d7ed-9307360c0d5c"
      },
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210818-054615\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 25ms/step - loss: 0.5043 - accuracy: 0.7886 - val_loss: 0.4572 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4153 - accuracy: 0.8140 - val_loss: 0.4386 - val_accuracy: 0.8084\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4017 - accuracy: 0.8229 - val_loss: 0.4343 - val_accuracy: 0.8071\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3939 - accuracy: 0.8256 - val_loss: 0.4293 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3862 - accuracy: 0.8273 - val_loss: 0.4282 - val_accuracy: 0.8189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDSOGvAdmTmZ",
        "outputId": "f3db6459-03c3-4e74-c79f-99db072457e7"
      },
      "source": [
        "# Make predictions on the model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17686911],\n",
              "       [0.7771318 ],\n",
              "       [0.9886696 ],\n",
              "       [0.20796344],\n",
              "       [0.7469005 ],\n",
              "       [0.7143102 ],\n",
              "       [0.9810847 ],\n",
              "       [0.97433144],\n",
              "       [0.94391453],\n",
              "       [0.13107583]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaGTICiImwmf",
        "outputId": "3b22bda1-e48e-4dbe-8621-d687a469b913"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5aodndRm8xx",
        "outputId": "3f9943d4-5d8c-4fe3-e1a4-3e087d661b69"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.88976377952756,\n",
              " 'f1': 0.817984880977007,\n",
              " 'precision': 0.8196605460013572,\n",
              " 'recall': 0.8188976377952756}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7b2NDF0nK3j",
        "outputId": "35c27253-4843-4da6-f1af-4784024ce71c"
      },
      "source": [
        "# Compare to baseline model\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.89, Difference: 2.62\n",
            "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
            "Baseline recall: 0.79, New recall: 0.82, Difference: 0.03\n",
            "Baseline f1: 0.79, New f1: 0.82, Difference: 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KNAPtR-nSnu"
      },
      "source": [
        "## Model 7: Tensorflow Hub pretrained sentence encoder on 10% of training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7gRaQOpninN"
      },
      "source": [
        "# Split the training data into 90/10 ratios\n",
        "train_sentences_90_percent, train_sentences_10_percent, train_labels_90_percent, train_labels_10_percent = train_test_split(np.array(train_sentences),\n",
        "                                                                                                                            train_labels,\n",
        "                                                                                                                            test_size=0.1,\n",
        "                                                                                                                            random_state=42\n",
        "                                                                                                                            )"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrl0U7ivoLID",
        "outputId": "410efb5a-e6cd-438b-d380-8e1df97d5a4c"
      },
      "source": [
        "# Check the length of targets in out subset of data\n",
        "pd.Series(train_labels_10_percent).value_counts()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    415\n",
              "1    271\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niszav__oa2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f092d92c-79c6-4985-d672-4d98bd306f5e"
      },
      "source": [
        "# Clone model 6 but reset weights\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get summary\n",
        "model_7.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSVuwhDvs6bw",
        "outputId": "1584e081-aac5-4102-c0e1-abeef7ebf0e7"
      },
      "source": [
        "# Fit the model on 10% training data\n",
        "model_7_history = model_7.fit(x=train_sentences_10_percent,\n",
        "                              y=train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence encoder\")])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence encoder/20210818-054637\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 120ms/step - loss: 0.6702 - accuracy: 0.7085 - val_loss: 0.6492 - val_accuracy: 0.7100\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.6013 - accuracy: 0.7915 - val_loss: 0.5958 - val_accuracy: 0.7388\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.5235 - accuracy: 0.8163 - val_loss: 0.5401 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.4597 - accuracy: 0.8324 - val_loss: 0.5089 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.4147 - accuracy: 0.8367 - val_loss: 0.4911 - val_accuracy: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h19LxCngt_OG",
        "outputId": "8c58519f-d75a-4b55-e54b-1b168ef72d6d"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25069603],\n",
              "       [0.8008594 ],\n",
              "       [0.88694865],\n",
              "       [0.329461  ],\n",
              "       [0.5166626 ],\n",
              "       [0.8128514 ],\n",
              "       [0.8160469 ],\n",
              "       [0.8573748 ],\n",
              "       [0.83087504],\n",
              "       [0.10663972]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32p9ZiygWIOp",
        "outputId": "137903f2-3599-43cd-efcf-ab2808ea53e2"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mipH927_WbD2",
        "outputId": "b39641ae-da89-420f-ff7f-b3973d9f5e4a"
      },
      "source": [
        "# Calculate model results\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'f1': 0.779088324447517,\n",
              " 'precision': 0.7868451603977311,\n",
              " 'recall': 0.7821522309711286}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzxoF-MuWouZ",
        "outputId": "551aae8a-c866-41b5-9cd2-233882508cd5"
      },
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_7_results)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.22, Difference: -1.05\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TXuN7wuW0ZH"
      },
      "source": [
        "# Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "V2wnEZs0XKtb",
        "outputId": "83b2fe5f-0685-45f6-ec6f-3d3cb0ec9b69"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame ({\"baseline\": baseline_results,\n",
        "                                   \"simple_dense\": model_1_results,\n",
        "                                   \"lstm\": model_2_results,\n",
        "                                   \"gru\" : model_3_results,\n",
        "                                   \"bidirectional\": model_4_results,\n",
        "                                   \"conv1d\": model_5_results,\n",
        "                                   \"tf_hub_sentence_encoder\": model_6_results,\n",
        "                                   \"tf_hub_10_percent_data\": model_7_results\n",
        "})\n",
        "\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.871391</td>\n",
              "      <td>0.795344</td>\n",
              "      <td>0.788714</td>\n",
              "      <td>0.785215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>77.296588</td>\n",
              "      <td>0.774276</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.771095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>77.952756</td>\n",
              "      <td>0.781115</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.777651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>77.034121</td>\n",
              "      <td>0.771825</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.768323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>75.853018</td>\n",
              "      <td>0.758485</td>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.757313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.889764</td>\n",
              "      <td>0.819661</td>\n",
              "      <td>0.818898</td>\n",
              "      <td>0.817985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>78.215223</td>\n",
              "      <td>0.786845</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.779088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "baseline                 79.265092   0.811139  0.792651  0.786219\n",
              "simple_dense             78.871391   0.795344  0.788714  0.785215\n",
              "lstm                     77.296588   0.774276  0.772966  0.771095\n",
              "gru                      77.952756   0.781115  0.779528  0.777651\n",
              "bidirectional            77.034121   0.771825  0.770341  0.768323\n",
              "conv1d                   75.853018   0.758485  0.758530  0.757313\n",
              "tf_hub_sentence_encoder  81.889764   0.819661  0.818898  0.817985\n",
              "tf_hub_10_percent_data   78.215223   0.786845  0.782152  0.779088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrYNBB8nYOO1"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "mQl7Eac8YgSp",
        "outputId": "5b583e89-abf4-4fb8-c4a7-0081a2022db6"
      },
      "source": [
        "# Plot and compare all of the models\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "VlxWuPjVY1lk",
        "outputId": "c50e7338-baa0-439c-80f7-e4520e24f728"
      },
      "source": [
        "# Sort model results by f1 score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b1a217890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUEHcCDZXsB"
      },
      "source": [
        "# Combining our Models\n",
        "\n",
        "Many production systems use an ensemble (multiple different models combined) of models to make a prediction. The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by singular model. Uncorrelated means different kinds of models like models that use different algorithms. There are a few ways we can combine our models:\n",
        "* Averaging - Take the output prediction probabilities of each model for each sample, combine them and average them.\n",
        "* Majority Vote - Make class predictions with each of your models on all samples, the predicted class is the one in majority.\n",
        "* Model Stacking - Take the outputs of each of your chosen models and use them as inputs to another model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efjaseMUz2h4",
        "outputId": "7b8afb5c-0dca-4b6d-b8c1-99a1eeaf94ea"
      },
      "source": [
        "# Get mean pred probs for 3 models\n",
        "baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get prediction probabilities from baseline model\n",
        "combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n",
        "combined_preds = tf.round(combined_pred_probs/3)\n",
        "combined_preds[:20]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNs6xNe91206",
        "outputId": "7ad1bee9-3102-4636-fd5c-fed987445b6e"
      },
      "source": [
        "# Calculate results from averaging the prediction probabilities\n",
        "ensemble_results = calculate_results(val_labels, combined_preds)\n",
        "ensemble_results"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'f1': 0.7725599551282146,\n",
              " 'precision': 0.7726074857232031,\n",
              " 'recall': 0.7729658792650919}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY1daH522Pom"
      },
      "source": [
        "# Add our combined model's results to the results DataFrame\n",
        "all_model_results.loc[\"ensemble_results\"] = ensemble_results"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qthz34Se2i78"
      },
      "source": [
        "# Convert the accuracy to the same scale as the rest of the results\n",
        "all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "XJojY82D2_-0",
        "outputId": "106307cf-5558-48a7-bd94-b6741733dfcb"
      },
      "source": [
        "all_model_results"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>0.788714</td>\n",
              "      <td>0.795344</td>\n",
              "      <td>0.788714</td>\n",
              "      <td>0.785215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.774276</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.771095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.781115</td>\n",
              "      <td>0.779528</td>\n",
              "      <td>0.777651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.771825</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.768323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.758485</td>\n",
              "      <td>0.758530</td>\n",
              "      <td>0.757313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>0.818898</td>\n",
              "      <td>0.819661</td>\n",
              "      <td>0.818898</td>\n",
              "      <td>0.817985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_10_percent_data</th>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.786845</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.779088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ensemble_results</th>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.772607</td>\n",
              "      <td>0.772966</td>\n",
              "      <td>0.772560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         accuracy  precision    recall        f1\n",
              "baseline                 0.792651   0.811139  0.792651  0.786219\n",
              "simple_dense             0.788714   0.795344  0.788714  0.785215\n",
              "lstm                     0.772966   0.774276  0.772966  0.771095\n",
              "gru                      0.779528   0.781115  0.779528  0.777651\n",
              "bidirectional            0.770341   0.771825  0.770341  0.768323\n",
              "conv1d                   0.758530   0.758485  0.758530  0.757313\n",
              "tf_hub_sentence_encoder  0.818898   0.819661  0.818898  0.817985\n",
              "tf_hub_10_percent_data   0.782152   0.786845  0.782152  0.779088\n",
              "ensemble_results         0.772966   0.772607  0.772966  0.772560"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYw32Mre3DBT"
      },
      "source": [
        "# Saving and Loading a trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q42hUZzHOeg"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HD5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoBtigMDHVmV"
      },
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 formay)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFMJTPPPHyWy",
        "outputId": "5a5ee54e-2642-489f-f4eb-7fb4492520e8"
      },
      "source": [
        "# How does our loaded model perform\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4282 - accuracy: 0.8189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4282020330429077, 0.8188976645469666]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqfb2FQ0H8bz",
        "outputId": "8e697006-776c-43e5-cb6f-b8993e334ee5"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceH3Ag35IK0m"
      },
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQgkoQ-vIb5b",
        "outputId": "44ce9709-ee3f-4c40-f7ec-c868810e1e6d"
      },
      "source": [
        "# Evaluate loaded savedmodel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4282 - accuracy: 0.8189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4282020330429077, 0.8188976645469666]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omNOPOLQImEJ"
      },
      "source": [
        "# Finding the most wrong examples in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "okYGGOhLI9Y5",
        "outputId": "b3d9f3f8-f973-462e-fd14-3644b06c8cce"
      },
      "source": [
        "# Create dataframe with validation sentences and best perfomring model preditctions\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n",
        "\n",
        "val_df.head(10)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.777132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.207963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.746900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Investigators rule catastrophic structural fai...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.714310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How the West was burned: Thousands of wildfire...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.981085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Map: Typhoon Soudelor's predicted path as it a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.974331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ûª93 blasts accused Yeda Yakub dies in Karach...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.943915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>My ears are bleeding  https://t.co/k5KnNwugwT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131076</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.176869\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.777132\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988670\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.207963\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.746900\n",
              "5  Investigators rule catastrophic structural fai...       1   1.0   0.714310\n",
              "6  How the West was burned: Thousands of wildfire...       1   1.0   0.981085\n",
              "7  Map: Typhoon Soudelor's predicted path as it a...       1   1.0   0.974331\n",
              "8  Ûª93 blasts accused Yeda Yakub dies in Karach...       1   1.0   0.943915\n",
              "9      My ears are bleeding  https://t.co/k5KnNwugwT       0   0.0   0.131076"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "D9fLb5seJfWn",
        "outputId": "0af9e4a0-2d99-408b-da5b-1732b8ce1aa3"
      },
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.930531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.882908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.877593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.858503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.844712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.839270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>The Sound of Arson</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.831637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.817798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>Deaths 3 http://t.co/nApviyGKYK</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.807168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.802785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.930531\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.882908\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.877593\n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.858503\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.844712\n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.839270\n",
              "144                                 The Sound of Arson       0   1.0   0.831637\n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.817798\n",
              "381                    Deaths 3 http://t.co/nApviyGKYK       0   1.0   0.807168\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.802785"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe16dfWUKC4C",
        "outputId": "5c6aa0a6-9405-48ec-f793-f7a4b9f3a640"
      },
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples(): # loop through the top 10 rows (change the index to view different rows)\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9305312633514404\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8829075694084167\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8775930404663086\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8585025072097778\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8447118401527405\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.839269757270813\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8316368460655212\n",
            "Text:\n",
            "The Sound of Arson\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8177981376647949\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8071678280830383\n",
            "Text:\n",
            "Deaths 3 http://t.co/nApviyGKYK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.8027852177619934\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAhKmAPwK9eU",
        "outputId": "2a7eb693-f404-44c8-bc6e-c543ce5ebc2b"
      },
      "source": [
        "# Check the most wrong false negatives (model predicted 0 when should've predicted 1)\n",
        "for row in most_wrong[-10:].itertuples(): # the last rows in the dataframe contain the false negatives\n",
        "  _, text, target, pred, prob = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1, Pred: 0, Prob: 0.07492450624704361\n",
            "Text:\n",
            "VICTORINOX SWISS ARMY DATE WOMEN'S RUBBER MOP WATCH 241487 http://t.co/yFy3nkkcoH http://t.co/KNEhVvOHVK\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.07192434370517731\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.07190728932619095\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.07145275920629501\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05689367279410362\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.05533766373991966\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.054375406354665756\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.0493430495262146\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.042971983551979065\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.033783137798309326\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}